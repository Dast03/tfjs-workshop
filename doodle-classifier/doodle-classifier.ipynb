{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify \"Quick, draw!\" drawings\n",
    "\n",
    "\"Can a neural network learn to recognize doodling?\" - [quickdraw.withgoogle.com][quickdraw]\n",
    "\n",
    "<a href=\"https://quickdraw.withgoogle.com/\">\n",
    "    <img src=\"images/quick-draw.png\" width=\"400px\" />\n",
    "</a>\n",
    "\n",
    "[quickdraw]:https://quickdraw.withgoogle.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download \"QuickDraw\" data\n",
    "---\n",
    "\n",
    "Download **Numpy bitmap files .npy** - [npy files from Google Cloud][quickdraw-npy] / [GitHub repository][quickdraw-github]\n",
    "\n",
    "[quickdraw-npy]:https://console.cloud.google.com/storage/quickdraw_dataset/full/numpy_bitmap\n",
    "[quickdraw-github]:https://github.com/googlecreativelab/quickdraw-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Execute this cell to download data using \"wget\" (linux/mac)\n",
    "files = {\n",
    "    'plane': 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy',\n",
    "    'car': 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/car.npy',\n",
    "    'cat': 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cat.npy',\n",
    "    'ship': 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cruise%20ship.npy',\n",
    "    'bird': 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bird.npy',\n",
    "    'sheep': 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sheep.npy',\n",
    "    'strawberry': 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/strawberry.npy',\n",
    "    'flower': 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flower.npy',\n",
    "    'chair': 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/chair.npy',\n",
    "    'book': 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/book.npy'\n",
    "    # Todo - add more classes from the Google Cloud page!\n",
    "}\n",
    "!mkdir -p 'data'\n",
    "for c, url in files.items():\n",
    "    !wget '{url}' -O 'data/{c}.npy' -q --show-progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# List .npy files and classes\n",
    "npy_files = glob.glob('data/*.npy')\n",
    "print('Files:', npy_files)\n",
    "\n",
    "classes = [os.path.splitext(os.path.basename(path))[0] for path in npy_files]\n",
    "print('Class names:', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a \"QuickDraw\" data set\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Create a class for our data set\n",
    "class QuickDraw():\n",
    "    def __init__(self, npy_files, max_img_per_class=np.inf):\n",
    "        # Open .npy files\n",
    "        self.X_list = [np.load(f, mmap_mode='r') for f in npy_files]\n",
    "        self.lengths = [min(len(X), max_img_per_class) for X in self.X_list]\n",
    "        \n",
    "        self.n_images = sum(self.lengths)\n",
    "        self.n_classes = len(npy_files)\n",
    "        \n",
    "    def get_pixels(self, idx):\n",
    "        for label, (X, l) in enumerate(zip(self.X_list, self.lengths)):\n",
    "            if idx < l:\n",
    "                return X[idx], label\n",
    "            idx -= l\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get image\n",
    "        img, label = self.get_pixels(idx)\n",
    "        img = img.reshape(28, 28) # Reshape\n",
    "        img = 255 - img # White background\n",
    "        \n",
    "        return img, label\n",
    "    \n",
    "# Create the data set\n",
    "quickdraw = QuickDraw(npy_files, max_img_per_class=5000)\n",
    "print('Total size:', quickdraw.n_images)\n",
    "\n",
    "img, label = quickdraw[0]\n",
    "print('First image:', classes[label])\n",
    "Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Keras data generators\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# Create a class for our data set\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, dataset, idxs, batch_size):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.idxs = idxs.copy() # We shuffle images between epochs: safer to work on a copy!\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Compute the number of batches\n",
    "        return int(np.floor(len(self.idxs)/self.batch_size))\n",
    "            \n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.idxs) # Shuffle images after each epoch\n",
    "\n",
    "    def __getitem__(self, i_batch):\n",
    "        # Load batch of images\n",
    "        imgs, labels = [], []\n",
    "        for idx in self.idxs[i_batch*self.batch_size:(i_batch+1)*self.batch_size]:\n",
    "            img, label = self.dataset[idx]\n",
    "    \n",
    "            # Preprocess image for keras\n",
    "            img = np.array(img, dtype=np.float32).reshape(28, 28, 1)\n",
    "            img = img/255 # Normalize (from 0..255 to 0..1)\n",
    "            imgs.append(img)\n",
    "            \n",
    "            # One-hot encode labels\n",
    "            oh_labels = keras.utils.to_categorical(label, num_classes=self.dataset.n_classes)\n",
    "            labels.append(oh_labels)\n",
    "        \n",
    "        return np.array(imgs), np.array(labels)\n",
    "    \n",
    "# Define train/validation sets\n",
    "idx = np.arange(quickdraw.n_images)\n",
    "np.random.shuffle(idx) # Shuffle data points\n",
    "\n",
    "valid_size = 1000\n",
    "train_idxs = idx[:-valid_size]\n",
    "valid_idxs = idx[-valid_size:]\n",
    "\n",
    "# Create data generators\n",
    "train_generator = DataGenerator(quickdraw, train_idxs, 32)\n",
    "valid_generator = DataGenerator(quickdraw, valid_idxs, 32)\n",
    "\n",
    "imgs, labels = train_generator[0]\n",
    "print('First images:', imgs.shape, imgs.dtype, 'min/max:', imgs.min(), imgs.max())\n",
    "print('Classes:', labels.shape, labels.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize predictions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot a few batches\n",
    "def plot_predictions(imgs, preds):\n",
    "    # Set number of rows/columns in plot\n",
    "    ncols = 8\n",
    "    nrows = int(np.ceil(len(imgs)/ncols))\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(ncols, nrows))\n",
    "    for i_ax, ax in enumerate(axes.flatten()):\n",
    "        if i_ax < len(imgs):\n",
    "            # Get image and prediction\n",
    "            img, label = imgs[i_ax, :, :, 0], np.argmax(preds[i_ax])\n",
    "            \n",
    "            # Plot them\n",
    "            ax.imshow(img, cmap=plt.cm.gray)\n",
    "            ax.set_title(classes[label], transform=ax.transAxes)\n",
    "\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Plot images with true labels\n",
    "imgs, labels = train_generator[0]\n",
    "plot_predictions(imgs, preds=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Network\n",
    "---\n",
    "\n",
    "\"Make some assumptions about the inputs to make learning more efficient\" - [Andrej Karpathy Lecture][karpathy-lecture]\n",
    "\n",
    "<a href=\"https://youtu.be/Y1ugnb0bobk\">\n",
    "    <img src=\"https://img.youtube.com/vi/Y1ugnb0bobk/maxresdefault.jpg\" width=\"400px\" />\n",
    "</a>\n",
    "\n",
    "[karpathy-lecture]:https://youtu.be/u6aEYuemt0M?t=10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1st option) Dense Network\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=len(classes), activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2nd option) Convolutional Network\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(filters=16, kernel_size=5, strides=2, activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "model.add(keras.layers.Conv2D(filters=16, kernel_size=3, strides=1, activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units=len(classes), activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trick: end training when accuracy stops improving (optional)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=2)\n",
    "\n",
    "# Train model\n",
    "history = model.fit_generator(\n",
    "    generator=train_generator, epochs=20,\n",
    "    validation_data=valid_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "\n",
    "# Plot loss values\n",
    "ax1.set_title('loss: {:.4f}'.format(history.history['val_loss'][-1]))\n",
    "ax1.plot(history.history['val_loss'], label='validation')\n",
    "ax1.plot(history.history['loss'], label='training')\n",
    "ax1.legend()\n",
    "\n",
    "# plot accuracy values\n",
    "ax2.set_title('accuracy: {:.2f}%'.format(history.history['val_acc'][-1]*100))\n",
    "ax2.plot(history.history['val_acc'], label='validation')\n",
    "ax2.plot(history.history['acc'], label='training')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images with true labels\n",
    "imgs, labels = train_generator[0]\n",
    "preds = model.predict(imgs)\n",
    "plot_predictions(imgs, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save and export model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('data', 'doodle-model.h5')\n",
    "tfjs_target_dir = os.path.join('data', 'tfjs')\n",
    "\n",
    "# Save model\n",
    "keras.models.save_model(model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running the notebook via [Google Colab](https://colab.research.google.com/), run\n",
    "\n",
    "```bash\n",
    "!pip install tensorflowjs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Prepare model for TensorFlow.js\n",
    "!tensorflowjs_converter --input_format keras '{model_path}' '{tfjs_target_dir}'\n",
    "\n",
    "# Zip the result!\n",
    "zip_file = os.path.join('data', 'tjfs-model')\n",
    "shutil.make_archive(zip_file, 'zip', tfjs_target_dir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save class names\n",
    "classes_file = os.path.join('data', 'classes.json')\n",
    "with open(classes_file, 'w') as f:\n",
    "    json.dump(classes, f)\n",
    "    \n",
    "!head '{classes_file}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
